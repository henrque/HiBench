    1  sudo su
    2  ssh-copy-id tcc-henrique
    3  vi /etc/hosts
    4  ssh-keygen -t rsa -b 4096
    5  ssh-copy-id tcc-henrique
    6  sudo su
    7  ls
    8  cd ..
    9  ls
   10  cd ..
   11  ls
   12  cd ../
   13  cd 
   14  ls
   15  sudo su
   16  exit
   17  sudo vi ../etc/passwd
   18  ls
   19  vi ~/.bashrc 
   20  source ~/.bashrc 
   21  vi ~/.bashrc 
   22  source ~/.bashrc 
   23  java -version
   24  vi /opt/hadoop/etc/hadoop/hadoop-env.sh 
   25  vi /opt/hadoop/etc/hadoop/core-site.xml 
   26  vi /opt/hadoop/etc/hadoop/hdfs-site.xml 
   27  hdfs namenode -format
   28  start-dfs.sh
   29  jpa
   30  jps
   31  hdfs dfs -mkdir /user
   32  hdfs dfs -mkdir /user/tcc-henrique
   33  hdfs dfs -mkdir input
   34  hdfs dfs -put /opt/hadoop/etc/hadoop/*.xml input
   35  $ hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar grep input output 'dfs[a-z.]+'
   36  hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar grep input output 'dfs[a-z.]+'
   37  hdfs dfs -cat output/*
   38  hdfs dfs -ls
   39  hdfs dfs -ls output/
   40  stop-dfs.sh 
   41  vi /opt/hadoop/etc/hadoop/mapred-site.xml 
   42  vi /opt/hadoop/etc/hadoop/yarn-site.xml 
   43  start-yarn.sh
   44  start-dfs.sh 
   45  jps
   46  hdfs dfs -mkdir books
   47  cd ~
   48  ls
   49  hdfs dfs -put alice.txt holmes.txt frankenstein.txt books
   50  yarn jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar wordcount "books/*" output
   51  ls
   52  hdfs dfs -rm -f output
   53  hdfs dfs -rm output
   54  hdfs dfs -ls
   55  hdfs dfs -rm -r -f output
   56  hdfs dfs -ls
   57  yarn jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar wordcount "books/*" output
   58  hdfs dfs -ls output
   59  cd /opt
   60  ls
   61  sudo tar -xvf spark-3.3.2-bin-hadoop3.tgz spark
   62  sudo tar -xvf spark-3.3.2-bin-hadoop3.tgz 
   63  ls
   64  sudo mv spark-3.3.2-bin-hadoop3 spark
   65  ls
   66  sudo chown tcc-henrique:tcc-henrique -r /opt/spark
   67  sudo chown tcc-henrique:tcc-henrique -R /opt/spark
   68  vi ~/.bashrc 
   69  source ~/.bashrc
   70  mv /opt/spark/conf/spark-defaults.conf.template /opt/spark/conf/spark-defaults.conf
   71  sudo vi /opt/spark/conf/spark-defaults.conf 
   72  spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi /opt/examples/jars/spark-examples_2.12-3.3.2.jar 10
   73  spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi /opt/hadoop/spark/examples/jars/spark-examples_2.12-3.0.1.jar 10
   74  spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.3.2.jar 10
   75  vi ~/.bashrc 
   76  source ~/.bashrc 
   77  spark-submit --deploy-mode client --class org.apache.spark.examples.SparkPi /opt/spark/examples/jars/spark-examples_2.12-3.3.2.jar 10
   78  ls
   79  cd /opt
   80  ls\
   81  ls
   82  bash
   83  ls
   84  cd /opt
   85  ls
   86  ls hadoop
   87  ls /opt/hadoop/
   88  ls
   89  sudo mv hadoop hadoop.tgz
   90  sudo tar -xvf hadoop.tgz 
   91  ls
   92  sudo mv hadoop-3.3.4 hadoop
   93  ls
   94  ls ..
   95  ls ../home/
   96  ls ../home/tcc-henrique/
   97  /u
   98  sudo chown tcc-henrique:tcc-henrique -R /opt/hadoop
   99  sudo chown tcc-henrique:tcc-henrique -R /opt/hadoop/
  100  ls
  101  cd ~
  102  ls
  103  wget -O alice.txt https://www.gutenberg.org/files/11/11-0.txt
  104  wget -O holmes.txt https://www.gutenberg.org/files/1661/1661-0.txt
  105  wget -O frankenstein.txt https://www.gutenberg.org/files/84/84-0.txt
  106  ls
  107  hdfs dfs -put alice.txt holmes.txt frankenstein.txt books
  108  apt install icewm
  109  sudo su
  110  ip a
  111  sudo su
  112  ifcondig
  113  ifconfig
  114  ip a
  115  ping 8.8.8.8
  116  ls
  117  mkdir tcc
  118  mkdir tcc/benchmark
  119  ls tcc/benchmark
  120  ls
  121  cd tcc/benchmark
  122  git clone https://github.com/Intel-bigdata/HiBench.git
  123  ls
  124  git clone https://github.com/Intel-bigdata/HiBench.git
  125  git config --global https.postBuffer 1048576000
  126  git clone https://github.com/Intel-bigdata/HiBench.git
  127  ping 8.8.8.8
  128  export GIT_TRACE_PACKET=1; export GIT_TRACE=1; export GIT_CURL_VERBOSE=1
  129  git clone https://github.com/Intel-bigdata/HiBench.git
  130  export GIT_TRACE_PACKET=0; export GIT_TRACE=0; export GIT_CURL_VERBOSE=0
  131  ls 
  132  vi ~/.bashrc 
  133  start-dfs.sh 
  134  start-yarn.sh 
  135  jps
  136  hdfs dfs -ls
  137  stop-yarn.sh
  138  stop-dfs.sh 
  139  start-yarn.sh 
  140  jps
  141  hdfs dfs -ls
  142  ls /opt/hadoop/etc/hadoop/core-site.xml 
  143  vi /opt/hadoop/etc/hadoop/core-site.xml 
  144  jps
  145  start-dfs.sh 
  146  jps
  147  hdfs dfs -ls
  148  telnet localhost 9000
  149  telnet tcc-henrique 9000
  150  ls tcc/benchmark/
  151  ls tcc/benchmark/HiBench/
  152  ls
  153  cd tcc/benchmark/
  154  ls HiBench/
  155  ls HiBench/.git/
  156  ip a
  157  ping 8.8.8.8
  158  ip a
  159  ls
  160  ip a
  161  python
  162  python3
  163  cp HiBench/conf/hadoop.conf.template  HiBench/conf/hadoop.conf
  164  ls
  165  ls HiBench/
  166  ls HiBench/conf/
  167  vi HiBench/conf/hadoop.conf
  168  cp HiBench/conf/spark.conf.template  HiBench/conf/spark.conf
  169  vi HiBench/conf/spark.conf
  170  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh 
  171  vi HiBench/conf/hadoop.conf
  172  vi HiBench/conf/hadoop.conf.template 
  173  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh 
  174  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ./books
  175  vi HiBench/conf/hibench.conf 
  176  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh 
  177  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ./books
  178  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh books
  179  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  180  vi HiBench/conf/hadoop.conf.template 
  181  vi HiBench/conf/hadoop.conf
  182  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  183  startx
  184  shutdown -h now
  185  start-dfs.sh & start-yarn.sh
  186  jps
  187  hdfs dfs -ls
  188  telnet tcc-henrique 9000
  189  vi /opt/hadoop/etc/hadoop/core-site.xml 
  190  stop-dfs.sh 
  191  stop-yarn..sh 
  192  stop-yarn.sh 
  193  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  194  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ~/alice.txt 
  195  cd tcc/benchmark/
  196  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ~/alice.txt 
  197  ip a
  198  vi HiBench/conf/hadoop.conf
  199  vi HiBench/conf/hibench.conf 
  200  vi HiBench/conf/workloads/streaming/wordcount.conf 
  201  vi HiBench/conf/workloads/micro/wordcount.conf 
  202  vi HiBench/conf/hibench.conf 
  203  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ~/alice.txt 
  204  vi HiBench/conf/hibench.conf 
  205  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ~/alice.txt 
  206  vi HiBench/conf/hibench.conf 
  207  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh ~/alice.txt 
  208  hdfs dfs -put alice.txt holmes.txt frankenstein.txt books
  209  vi /etc/hostname
  210  vi /etc/hosts
  211  startx
  212  shutdown -h now
  213  exit
  214  history | less -prepare
  215  start-dfs.sh 
  216  start-yarn.sh 
  217  jps
  218  ls
  219  cd tcc/benchmark/
  220  hdfs dfs -ls
  221  vi /opt/hadoop/etc/hadoop/hdfs-site.xml 
  222  vi /opt/hadoop/etc/hadoop/core-site.xml 
  223  hdfs dfs -ls
  224  stop-dfs.sh 
  225  stop-yarn.sh 
  226  JPS
  227  jps
  228  ping tcc-henrique
  229  ping tcc-henrique:9000
  230  ip a
  231  ssh tcc-henrique
  232  vi /opt/hadoop/etc/hadoop/hadoop-env.
  233  vi /opt/hadoop/etc/hadoop/hadoop-env.sh 
  234  hdfs namenode -format
  235  start-dfs.sh
  236  hdfs dfs -mkdir /user
  237  hdfs dfs -mkdir /user/tcc-henrique
  238  hdfs dfs -mkdir books
  239  history | hdfs 
  240  history | less
  241  history | less | hdfs
  242  history | less - hdfs
  243  hdfs dfs -put alice.txt holmes.txt frankenstein.txt books
  244  hdfs dfs -put ~/alice.txt ~/holmes.txt ~/frankenstein.txt books
  245  start-yarn.sh
  246  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  247  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh books
  248  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh filename books
  249  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  250  ls
  251  vi HiBench/conf/hadoop.conf
  252  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  253  vi HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh 
  254  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  255  vi HiBench/conf/hadoop.conf
  256  vi HiBench/conf/hibench.conf
  257  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  258  vi HiBench/conf/hibench.conf
  259  HiBench/bin/workloads/micro/wordcount/prepare/prepare.sh
  260  HiBench/conf/hibench.conf | less -INPUT_HDFS
  261  vi HiBench/conf/hibench.conf | less -INPUT_HDFS
  262  netplan apply
  263  sudo su
  264  hdfs dfs -ls
  265  hdfs dfs -ls /
  266  hdfs dfs -ls /user
  267  hdfs dfs -ls
  268  hdfs dfs -mkdir HiBench
  269  ip a
  270  startx
  271  vi HiBench/conf/hibench.conf 
  272  cd tcc/benchmark/
  273  vi HiBench/conf/hibench.conf 
  274  mvn -Phadoopbench -Psparkbench -Dspark=3.1.2 -Dscala=2.11 clean package
  275  mvn
  276  sudo apt install maven
  277  mvn -Phadoopbench -Psparkbench -Dspark=3.1.2 -Dscala=2.11 clean package
  278  mvn -hadoopbench -sparkbench -Dspark=3.1.2 -Dscala=2.11 clean package
  279  mvn -Phadoopbench -Psparkbench -Dspark=3.1.2 -Dscala=2.11 clean package
  280  cd HiBench/
  281  mvn -Phadoopbench -Psparkbench -Dspark=3.1.2 -Dscala=2.11 clean package
  282  mvn -Phadoopbench -Psparkbench -Dspark=2.4 -Dscala=2.11 clean package
  283  java -version
  284  jva -V
  285  java -V
  286  java -v
  287  java -version
  288  scala -version
  289  mvn -Phadoopbench -Psparkbench -Dspark=3.0 -Dscala=2.12 clean package
  290  ls
  291  vi common/pom.xml 
  292  mvn -Phadoopbench -Psparkbench -Dspark=3.0 -Dscala=2.10 clean package
  293  mvn -Phadoopbench -Psparkbench  clean package
  294  mvn -Phadoopbench -Psparkbench -Dspark=3.0  clean package
  295  sudo apt install openjdk-8-jdk
  296  java -version
  297  sudo apt update
  298  sudo apt install openjdk-8-jdk
  299  vi ~/.bashrc 
  300  source ~/.bashrc 
  301  java -version
  302  sudo update-alternatives --config java
  303  java -version
  304  mvn -Phadoopbench -Psparkbench -Dspark=3.1 -Dscala=2.12 clean package
  305  bin/workloads/micro/wordcount/prepare/prepare.sh
  306  vi conf/spark.conf
  307  vi conf/hadoop.conf
  308  bin/workloads/micro/wordcount/prepare/prepare.sh
  309  shutdown -h now
  310  ls
  311  cd tcc/benchmark/HiBench/
  312  ls
  313* cd tcc/benchmark/HiBench/nput
  314  bin/workloads/micro/wordcount/prepare/prepare.sh Input
  315  start-dfs.sh
  316  start-yarn.sh
  317  jps
  318  hdfs dfs -ls
  319  history | less -format
